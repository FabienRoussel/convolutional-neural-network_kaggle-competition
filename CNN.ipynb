{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nfrom os import listdir, path\nfrom zipfile import ZipFile\nimport random\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.preprocessing.image import img_to_array, load_img\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, Model\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, Average,Input\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers\nfrom keras.callbacks import LearningRateScheduler\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nimport math as math\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"if not path.exists('../input/data_train/'):\n    print('Extracting cat image files...')\n    zf = ZipFile('../input/data_train.tar.gz')\n    zf.extractall('../input/')\nif not path.exists('../input/data_test/'):\n    print('Extracting dog image files...')\n    zf = ZipFile('../input/data_test.tar.gz')\n    zf.extractall('../input/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f726ac174f795a00c673f2ced0c6b8f6578da03"},"cell_type":"markdown","source":"# I. Load the data"},{"metadata":{"_uuid":"363266194f56fa6a74b957fc59dbcaf7f05eda5d"},"cell_type":"markdown","source":"You first need to create a way to sort the the list dir by alpha-numeral order."},{"metadata":{"trusted":true,"_uuid":"fc48e3651678f0f37c0aaa990d5377cf24385ec7"},"cell_type":"code","source":"import csv\nimport re\n\ndef sorted_aphanumeric(data):\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n    return sorted(data, key=alphanum_key)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2f46b89ddee8a826b8b83ff9068e6eb9a489076"},"cell_type":"markdown","source":"Create a function that load the data"},{"metadata":{"trusted":true,"_uuid":"10301fbd33a6670212cdfeda2789a3bfad48fd4b"},"cell_type":"code","source":"def load_splitted_data(image_size, classes, name_label):\n    X_train, Y_train, X_valid = [], [], []\n    print(\"Loading ...\")\n    with open(path.join('../input/',name_label), 'r') as csvFile:\n        reader = list(csv.reader(csvFile))\n        reader.pop(0)\n        for i, label in reader:\n            Y_train.append(label)\n    csvFile.close()\n    \n    class1, class2 = classes[0], classes[1]\n    files = sorted_aphanumeric(listdir(path.join('../input/', class1)))\n    for i, file in enumerate(files):\n        img = load_img(path.join('../input/', class1, file), target_size=image_size)\n        X_train.append(img_to_array(img))\n        \n    files = sorted_aphanumeric(listdir(path.join('../input/', class2)))\n    for i, file in enumerate(files):\n        img = load_img(path.join('../input/', class2, file), target_size=image_size)\n        #print(i, file)\n        X_valid.append(img_to_array(img))\n    print(\"Data loaded\")\n    return np.asarray(X_train, dtype=np.float32), np.asarray(Y_train), np.asarray(X_valid, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91b7ec1c2173fb0c0b49cb4889e10a883a27643c"},"cell_type":"code","source":"def scale_data(X_tr, X_val, return_scaler=False):\n    shape_tr, shape_val = X_tr.shape, X_val.shape\n    X_tr_flat = np.ravel(X_tr).reshape(-1, 1)\n    X_val_flat = np.ravel(X_val).reshape(-1, 1)\n    min_max_scaler = MinMaxScaler()\n    X_tr_scaled = min_max_scaler.fit_transform(X_tr_flat).reshape(shape_tr)\n    X_val_scaled = min_max_scaler.transform(X_val_flat).reshape(shape_val)\n    if not return_scaler:\n        return X_tr_scaled, X_val_scaled\n    else:\n        return X_tr_scaled, X_val_scaled, min_max_scaler\n    \ndef apply_scaling(X, scaler):\n    shape_X = X.shape\n    X_flat = np.ravel(X).reshape(-1, 1)\n    X_scaled = scaler.transform(X_flat).reshape(shape_X)\n    return X_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f92e0cbc00d5cf3d8d896bc0fe7ba83bbe97d45f"},"cell_type":"code","source":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n    for ax, metric, name in zip(axs, ['acc', 'loss'], ['Accuracy', 'Loss']):\n        ax.plot(\n            range(1, len(model_history.history[metric]) + 1), \n            model_history.history[metric]\n        )\n        ax.plot(\n            range(1, len(model_history.history['val_' + metric]) + 1), \n            model_history.history['val_' + metric]\n        )\n        ax.set_title('Model ' + name)\n        ax.set_ylabel(name)\n        ax.set_xlabel('Epoch')\n        ax.legend(['train', 'val'], loc='best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3144b7c5a465ee5abe1b9bd7ddf5cbba773ac19c"},"cell_type":"code","source":"from matplotlib import pyplot\nfrom scipy.misc import toimage\n\ndef show_imgs(X):\n    pyplot.figure(1,figsize=[8,8])\n    k = 0\n    for i in range(0,4):\n        for j in range(0,4):\n            pyplot.subplot2grid((4,4),(i,j))\n            pyplot.imshow(toimage(X[k]))\n            k = k+1\n    # show the plot\n    pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ba70082640a59e491abbc5bb23532455408ad50"},"cell_type":"code","source":"def lr_schedule(epoch):\n    lrate = 0.001\n    if epoch > 75:\n        lrate = 0.0005\n    elif epoch > 100:\n        lrate = 0.0003       \n    return lrate\n\ndef step_decay(epoch):\n    initial_lrate = 2e-3\n    drop = 0.65\n    epochs_drop = 25\n    lrate = initial_lrate * math.pow(drop, \n                                    math.floor((1+epoch)/epochs_drop))\n    return lrate\n\ndef lr_schedule_opti(epoch):\n    lrate = 0.001\n    drop = 0.65\n    epochs_drop = 25\n    if epoch > 75:\n        lrate = lrate/2\n    elif epoch > 100:\n        lrate = lrate * math.pow(drop, \n                math.floor((epoch - 50 )/epochs_drop))       \n    return lrate\n\nlrate1 = LearningRateScheduler(lr_schedule)\nlrate2 = LearningRateScheduler(step_decay)\nlrate3 = LearningRateScheduler(lr_schedule_opti)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef18af5005e90066960956f74e057faff27076b1"},"cell_type":"markdown","source":"Load the data. We fix a relatively small image_size (32, 32, 3) to avoid suffering from slow calculation"},{"metadata":{"trusted":true,"_uuid":"6ffb7499a5efdb44d370717b2614b5e852a4e751"},"cell_type":"code","source":"#image_size = (32, 32, 3)\nimage_size = (64, 64, 3)\nsample_size = 7200\nname_label = \"labels_train.csv\"\n\nclasses = ['data_train/data_train', 'data_test/data_test']\nX_train, Y_train, X_test = load_splitted_data(\n    image_size=image_size, classes=classes, name_label=name_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4218d3c31b1657df8fec8427f75623f69afd38c2"},"cell_type":"code","source":"print(X_train.shape, X_test.shape, Y_train.shape)\nX_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test, return_scaler=True)\nprint(X_train_scaled.shape, X_test_scaled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2871d499ccd905596d3634885c48269ffc1c032"},"cell_type":"code","source":"show_imgs(X_train[:16])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4d4134204d372f221c3d52c1baf4004256d2839"},"cell_type":"markdown","source":"For Training our model, we will need to validate the data"},{"metadata":{"trusted":true,"_uuid":"50116d004d930dcd2624e43c77b3a25457327cb4"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n#From label to int\nnum_classes = 15\nlabel_encoder = LabelEncoder()\none_hot_encoder = OneHotEncoder()\nY_train_LE = label_encoder.fit_transform(Y_train.ravel()).reshape(*Y_train.shape)\n#Y_train_LE = Y_train_LE.reshape(-1, 1)\n#Y_train_OH = one_hot_encoder.fit_transform(Y_train_LE)\n\n#X_tr, X_val, Y_tr, Y_val = train_test_split(X_train, Y_train_OH, test_size=0.2, random_state=42)\nX_tr, X_val, Y_tr, Y_val = train_test_split(X_train, Y_train_LE, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24d7025ea96dfba7d78ea962a48f3219d348d8c5"},"cell_type":"code","source":"X_tr = X_tr.astype('float32')\nX_val = X_val.astype('float32')\nX_test = X_test.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7fb26ee2f9d4f40b1951d3b488f452db97c5c08"},"cell_type":"code","source":"#X_tr = X_tr / 255.0\n#X_val = X_val / 255.0\n#X_test = X_test / 255.0\n#z-score\nmean = np.mean(X_tr,axis=(0,1,2,3))\nstd = np.std(X_tr,axis=(0,1,2,3))\nX_tr = (X_tr-mean)/(std+1e-7)\nX_val = (X_val-mean)/(std+1e-7)\nX_test = (X_test-mean)/(std+1e-7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2f05ade3a68128f5ffa99e6c9dd8069bf510d69"},"cell_type":"markdown","source":"# II. Create the neuronal network"},{"metadata":{"trusted":true,"_uuid":"8771bc1326e1a99bc5327ee3f4091f73236579a6"},"cell_type":"code","source":"weight_decay = 1e-4\ninput_shape = X_tr[0,:,:,:].shape\nmodel_input = Input(shape=input_shape)\nepochs = 100\n\ndef model1(model_input):\n    x = (Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(model_input)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2,2)))(x)\n    x = (Dropout(0.3))(x)\n\n    x = (Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2,2)))(x)\n    x = (Dropout(0.4))(x)\n\n    x = (Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2,2)))(x)\n    x = (Dropout(0.5))(x)\n\n    x = (Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Activation('elu'))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2,2)))(x)\n    x = (Dropout(0.7))(x)\n\n    x = (Flatten())(x)\n    x = (Dense(num_classes, activation='softmax'))(x)\n\n    model = Model(model_input, x, name='un')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aba043a4ee6c864c51b3bf0b5ed711a85e5d88c9"},"cell_type":"code","source":"def model2(model_input):\n    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding =    'same')(model_input)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (1, 1), activation='relu')(x)\n    x = Conv2D(num_classes, (1, 1))(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    \n    model = Model(model_input, x, name='conv_pool_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8bd3e79b31009094ce521c8a5b16ff8b1926028"},"cell_type":"code","source":"def model3(model_input):\n    x = (Conv2D(32, (3, 3), padding='same'))(model_input)\n    #model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.25))(x)\n\n    x = (Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=keras.constraints.maxnorm(3)))(x)\n    #model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.3))(x)\n\n    x = (Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=keras.constraints.maxnorm(3)))(x)\n    #model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.4))(x)\n\n    x = (Flatten())(x)\n    x = (Dense(512, activation='relu', kernel_constraint=keras.constraints.maxnorm(3)))(x)\n    x = (Dropout(0.6))(x)\n    x = (Dense(15, activation='softmax'))(x)\n\n    model = Model(model_input, x, name='trois')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fa6cdb46415d4a810b35051afafe59f506f7e5a"},"cell_type":"code","source":"def model4(model_input):\n    x = (Conv2D(32, (3, 3), padding='same'))(model_input)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.3))(x)\n\n    x = (Conv2D(64, (5, 5), activation='elu', padding='same', kernel_constraint=keras.constraints.maxnorm(3),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.3))(x)\n\n    x = (Conv2D(128, (3, 3), activation='elu', padding='same', kernel_constraint=keras.constraints.maxnorm(3),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (BatchNormalization())(x)\n    x = (MaxPooling2D(pool_size=(2, 2)))(x)\n    x = (Dropout(0.4))(x)\n\n    x = (Dense(256, activation='elu', kernel_constraint=keras.constraints.maxnorm(3),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n    x = (Dropout(0.6))(x)\n    \n    x = (Flatten())(x)\n    x = (Dense(num_classes, activation='softmax'))(x)\n\n    model = Model(model_input, x, name='quatre')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80cff6bbc1d8873943c011b56a6d3ae8be8ba862"},"cell_type":"code","source":"def model5(model_input):\n    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(192, (1, 1), activation='relu')(x)\n    x = Conv2D(num_classes, (1, 1))(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n        \n    model = Model(model_input, x, name='cinq')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2614e921a051bce5e80f1e0b5f1697d9bbaafef5"},"cell_type":"code","source":"from sklearn.utils import class_weight\n\ndef compile_and_train(model, num_epochs, X_tr, Y_tr, X_val, Y_val): \n    #data augmentation\n    datagen = ImageDataGenerator(\n        rotation_range=15,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,\n        )\n    datagen.fit(X_tr)\n\n    #training\n    batch_size = 128\n    num_epoches = num_epochs\n    print(X_tr.shape , Y_tr.shape, Y_val.shape)\n    dataFlow = datagen.flow(np.array(X_tr), Y_tr, batch_size=batch_size)\n\n    opt = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n    #opt = keras.optimizers.Adam(lr=0.001, decay=1e-5)\n    #opt = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    #filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n    #checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1)\n    #tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n    \n    model_history = model.fit_generator(dataFlow,\n                        steps_per_epoch=X_tr.shape[0] // batch_size,\n                        epochs=num_epoches,\n                        verbose=1,\n                        validation_data=(X_val,Y_val),\n                        validation_steps=X_val.shape[0] // batch_size,\n                        callbacks=[lrate3])\n    \n    return model, model_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78e9443ff3a55eca1e672ee52ebc4f92cda2ef94"},"cell_type":"code","source":"model_1 = model1(model_input)\nmodel_1, _ = compile_and_train(model_1, epochs, X_tr, Y_tr, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5114549acecc46925c4ba8e8340d185faca3a7"},"cell_type":"code","source":"model_2 = model2(model_input)\nmodel_2, _ = compile_and_train(model_2, 70, X_tr, Y_tr, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6302f55b0b12f430c0770d1ce407dcf55e8ee028"},"cell_type":"code","source":"model_3 = model3(model_input)\nmodel_3, _ = compile_and_train(model_3, epochs, X_tr, Y_tr, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fae28bf21d334a250bebaa9a326412937d959c0"},"cell_type":"code","source":"model_4 = model4(model_input)\nmodel_4, _ = compile_and_train(model_4, epochs, X_tr, Y_tr, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8773db5ebc08be6964690f94a5c56ecf49a1835a"},"cell_type":"code","source":"model_5 = model5(model_input)\nmodel_5, _ = compile_and_train(model_5, epochs, X_tr, Y_tr, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cc4ad357b9e988c4a7d796d820b1cba3521b1ce"},"cell_type":"code","source":"def ensemble(models):\n    input_img = Input(shape=input_shape)\n\n    outputs = [model(input_img) for model in models] # get the output of model given the input image\n    y = Average()(outputs)\n\n    model = Model(inputs=input_img, outputs=y, name='ensemble')\n    return model\n\nensemble_model = ensemble([model_1, model_2, model_3, model_4, model_5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16c9bee800281d5b1b9aa3bd0f6025c3ac58eb79"},"cell_type":"code","source":"def accuracy_ensemble(model):\n    Y_pred = model.predict(X_val, batch_size = 32)\n    Y_pred = np.argmax(Y_pred, axis=1)\n    print(Y_pred[0], Y_val)\n    accuracy = 0\n    for i in range(Y_val.shape[0]):\n        if Y_pred[i] == Y_val[i]:\n            accuracy  += 1\n    return accuracy/ Y_val.shape[0] \n\nprint(accuracy_ensemble(ensemble_model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad216ef394e45540e7dadf3ae0c80c1fb6aca69b"},"cell_type":"code","source":"#testing\nprint('\\nTest result: %.3f' % (accuracy_ensemble(ensemble_model)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d6b85198d441f03879878670dcf3b02c4257aee"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    #for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    #    plt.text(j, i, format(cm[i, j], fmt),\n    #             horizontalalignment=\"center\",\n    #             color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11e09cdc09c4586dc1a39d48f2c92adddb7069b6"},"cell_type":"code","source":"Y_val_pred = ensemble_model.predict(X_val, verbose=True)\nY_val_decode = np.argmax(Y_val_pred, axis=1)\nY_val_pred = label_encoder.inverse_transform(Y_val_decode)\nY_val_true = label_encoder.inverse_transform(Y_val)\n\ncnf_matrix = confusion_matrix(Y_val_true, Y_val_pred)\nnp.set_printoptions(precision=2)\n\nplt.figure(figsize=[10,10])\nplot_confusion_matrix(cnf_matrix, classes=list(label_encoder.classes_), normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe49e3e95b0074c3a2800bc63f8d7389c9e9bd2c"},"cell_type":"markdown","source":"# III. Predict the Test set and create a csv file"},{"metadata":{"trusted":true,"_uuid":"77858366fd7fa6fbb93bea6b2a65e65fd010a8a0"},"cell_type":"code","source":"Y_predict = ensemble_model.predict(X_test, verbose=True)\nfor i in range(0,100):\n    print(Y_predict[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a71a7bb97ba60c4e2367269c255105c026410cac","scrolled":false},"cell_type":"code","source":"Y_decode = np.argmax(Y_predict, axis=1)\nprint(list(label_encoder.classes_))\nfor i in range(0,100):\n    print(Y_decode[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb5d2a7df8f6f2530bb4ef2fc4c56350321a3c1a"},"cell_type":"code","source":"Y_predict = label_encoder.inverse_transform(Y_decode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9be87fc5f5d92377eb7cf56b6facf829090baad8"},"cell_type":"code","source":"data_to_submit = pd.DataFrame({\n    'Id':range(0, Y_predict.shape[0]),\n    'Category':Y_predict\n})\ndata_to_submit.to_csv('submission_test.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3649bbca390358d815ed32ed805f8c44def83100"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}